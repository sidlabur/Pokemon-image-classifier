{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage import filters\n",
    "from skimage.filters import unsharp_mask, sobel_h, sobel_v, prewitt_h, prewitt_v\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "data_dir = '../PokemonData'\n",
    "\n",
    "def blur_image(image):\n",
    "    return tf.numpy_function(lambda x: filters.gaussian(x, sigma=2, channel_axis=-1), [image], tf.float32)\n",
    "\n",
    "def sharpen_image(image):\n",
    "    return tf.numpy_function(lambda x: unsharp_mask(x, radius=1, amount=1), [image], tf.float32)\n",
    "\n",
    "def high_pass_filter(image):\n",
    "    original = image\n",
    "    blurred = filters.gaussian(image, sigma=2, channel_axis=-1)\n",
    "    high_pass = original - blurred\n",
    "    return high_pass\n",
    "\n",
    "def sobel_horizontal(image):\n",
    "    sobel_output = tf.numpy_function(lambda x: sobel_h(x[:,:,0]), [image], tf.float32)\n",
    "    sobel_output = tf.stack([sobel_output, sobel_output, sobel_output], axis=-1)\n",
    "    return sobel_output\n",
    "\n",
    "def sobel_vertical(image):\n",
    "    sobel_output = tf.numpy_function(lambda x: sobel_v(x[:,:,0]), [image], tf.float32)\n",
    "    sobel_output = tf.stack([sobel_output, sobel_output, sobel_output], axis=-1)\n",
    "    return sobel_output\n",
    "\n",
    "def prewitt_horizontal(image):\n",
    "    prewitt_output = tf.numpy_function(lambda x: prewitt_h(x[:,:,0]), [image], tf.float32)\n",
    "    prewitt_output = tf.stack([prewitt_output, prewitt_output, prewitt_output], axis=-1)\n",
    "    return prewitt_output\n",
    "\n",
    "def prewitt_vertical(image):\n",
    "    prewitt_output = tf.numpy_function(lambda x: prewitt_v(x[:,:,0]), [image], tf.float32)\n",
    "    prewitt_output = tf.stack([prewitt_output, prewitt_output, prewitt_output], axis=-1)\n",
    "    return prewitt_output\n",
    "\n",
    "def create_datagen(preprocessing_function=None):\n",
    "    return ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,\n",
    "        preprocessing_function=preprocessing_function\n",
    "    )\n",
    "\n",
    "def create_model(input_shape=(128, 128, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(150, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_dnn_model(input_shape=(128, 128, 3)):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(150, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(preprocessing_function=None, preprocessing_name=\"\", model_type=\"CNN\"):\n",
    "    start_time = time.time()\n",
    "    print(f\"Training with {preprocessing_name} preprocessing and {model_type} model...\")\n",
    "    datagen = create_datagen(preprocessing_function)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    if model_type == \"DNN\":\n",
    "        model = create_dnn_model()\n",
    "    elif model_type == \"Random Forest\":\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif model_type == \"Gradient Boosting\":\n",
    "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "    elif model_type == \"SVM\":\n",
    "        model = SVC(kernel='linear', random_state=42)\n",
    "    elif model_type == \"Logistic Regression\":\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    else:\n",
    "        model = create_model()\n",
    "\n",
    "    if model_type in [\"DNN\", \"CNN\"]:\n",
    "        model.fit(train_generator, epochs=10, validation_data=validation_generator, verbose=1)\n",
    "        _, accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    else:\n",
    "        train_features, train_labels = next(train_generator)\n",
    "        validation_features, validation_labels = next(validation_generator)\n",
    "        model.fit(train_features.reshape(len(train_features), -1), np.argmax(train_labels, axis=1))\n",
    "        accuracy = accuracy_score(np.argmax(validation_labels, axis=1), model.predict(validation_features.reshape(len(validation_features), -1)))\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Accuracy with {preprocessing_name} and {model_type}: {accuracy:.2f}\")\n",
    "    return accuracy, training_time, model_type + \" + \" + preprocessing_name\n",
    "\n",
    "preprocessing_techniques = [\n",
    "    (None, \"No Preprocessing\"),\n",
    "    (blur_image, \"Blur\"),\n",
    "    (sharpen_image, \"Sharpen\"),\n",
    "    (high_pass_filter, \"High-Pass Filter\"),\n",
    "    (sobel_horizontal, \"Sobel Horizontal\"),\n",
    "    (sobel_vertical, \"Sobel Vertical\"),\n",
    "    (prewitt_horizontal, \"Prewitt Horizontal\"),\n",
    "    (prewitt_vertical, \"Prewitt Vertical\")\n",
    "]\n",
    "\n",
    "model_types = [\"CNN\", \"DNN\", \"Random Forest\", \"Gradient Boosting\", \"SVM\", \"Logistic Regression\"]\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for model_type in model_types:\n",
    "    for preprocess_func, preprocess_name in preprocessing_techniques:\n",
    "        accuracy, training_time, description = train_and_evaluate(preprocess_func, preprocess_name, model_type)\n",
    "        metrics.append({\n",
    "            \"Model + Preprocessing\": description,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Training Time (s)\": training_time\n",
    "        })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"Model\": [\n",
    "        \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\",\n",
    "        \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\",\n",
    "        \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\",\n",
    "        \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\",\n",
    "        \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\",\n",
    "        \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\"\n",
    "    ],\n",
    "    \"Preprocessing\": [\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        0.923077, 0.615385, 0.769231, 0.769231, 0.769231, 0.769231, 0.846154, 0.923077,\n",
    "        0.692308, 0.461538, 0.769231, 0.615385, 0.692308, 0.384615, 0.615385, 0.538462,\n",
    "        0.846154, 0.692308, 0.538462, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231,\n",
    "        0.538462, 0.384615, 0.461538, 0.615385, 0.461538, 0.615385, 0.692308, 0.384615,\n",
    "        0.846154, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231,\n",
    "        0.769231, 0.538462, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231\n",
    "    ],\n",
    "    \"Training Time (s)\": [\n",
    "        48.058440, 56.633320, 48.027893, 48.898570, 63.238348, 51.686615, 56.045794, 48.915993,\n",
    "        45.766466, 44.351937, 51.481051, 54.415695, 52.088268, 48.996642, 48.366774, 47.622144,\n",
    "        1.163560, 2.405584, 3.167753, 1.905416, 1.142788, 1.001018, 1.211761, 1.163381,\n",
    "        16.167434, 12.488234, 6.066616, 23.346955, 13.848549, 12.097733, 16.955513, 17.397891,\n",
    "        1.285106, 1.356832, 1.021704, 1.614405, 1.079370, 1.373316, 1.764342, 1.508606,\n",
    "        110.745154, 126.193660, 4.222481, 10.666535, 8.093194, 11.186874, 17.907882, 8.518475\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Accuracy per Second'] = df['Accuracy'] / df['Training Time (s)']\n",
    "avg_accuracy_per_model = df.groupby('Model')['Accuracy'].mean().reset_index()\n",
    "avg_accuracy_per_filter = df.groupby('Preprocessing')['Accuracy'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(avg_accuracy_per_model['Model'], avg_accuracy_per_model['Accuracy'], color='skyblue')\n",
    "plt.title('Average Accuracy per Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(avg_accuracy_per_filter['Preprocessing'], avg_accuracy_per_filter['Accuracy'], color='lightgreen')\n",
    "plt.title('Average Accuracy per Filter')\n",
    "plt.xlabel('Preprocessing Filter')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \"Model\": [\n",
    "        \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\",\n",
    "        \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\", \"DNN\",\n",
    "        \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\", \"Random Forest\",\n",
    "        \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\", \"Gradient Boosting\",\n",
    "        \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\", \"SVM\",\n",
    "        \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\"\n",
    "    ],\n",
    "    \"Preprocessing Technique\": [\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\",\n",
    "        \"No Preprocessing\", \"Blur\", \"Sharpen\", \"High-Pass Filter\", \"Sobel Horizontal\", \"Sobel Vertical\", \"Prewitt Horizontal\", \"Prewitt Vertical\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        0.923077, 0.615385, 0.769231, 0.769231, 0.769231, 0.769231, 0.846154, 0.923077,\n",
    "        0.692308, 0.461538, 0.769231, 0.615385, 0.692308, 0.384615, 0.615385, 0.538462,\n",
    "        0.846154, 0.692308, 0.538462, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231,\n",
    "        0.538462, 0.384615, 0.461538, 0.615385, 0.461538, 0.615385, 0.692308, 0.384615,\n",
    "        0.846154, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231,\n",
    "        0.769231, 0.538462, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231, 0.769231\n",
    "    ],\n",
    "    \"Training Time (s)\": [\n",
    "        48.058440, 56.633320, 48.027893, 48.898570, 63.238348, 51.686615, 56.045794, 48.915993,\n",
    "        45.766466, 44.351937, 51.481051, 54.415695, 52.088268, 48.996642, 48.366774, 47.622144,\n",
    "        1.163560, 2.405584, 3.167753, 1.905416, 1.142788, 1.001018, 1.211761, 1.163381,\n",
    "        16.167434, 12.488234, 6.066616, 23.346955, 13.848549, 12.097733, 16.955513, 17.397891,\n",
    "        1.285106, 1.356832, 1.021704, 1.614405, 1.079370, 1.373316, 1.764342, 1.508606,\n",
    "        110.745154, 126.193660, 4.222481, 10.666535, 8.093194, 11.186874, 17.907882, 8.518475\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Accuracy to Second Ratio'] = df['Accuracy'] / df['Training Time (s)']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model in df['Model'].unique():\n",
    "    model_df = df[df['Model'] == model]\n",
    "    plt.plot(model_df['Preprocessing Technique'], model_df['Accuracy'], label=model)\n",
    "\n",
    "plt.xlabel('Preprocessing Technique', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('Comparison of Accuracy for Different Preprocessing Techniques', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model in df['Model'].unique():\n",
    "    model_df = df[df['Model'] == model]\n",
    "    plt.plot(model_df['Preprocessing Technique'], model_df['Accuracy to Second Ratio'], label=model)\n",
    "\n",
    "plt.xlabel('Preprocessing Technique', fontsize=14)\n",
    "plt.ylabel('Accuracy to Second Ratio', fontsize=14)\n",
    "plt.title('Comparison of Accuracy to Second Ratio for Different Preprocessing Techniques', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
